{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b39bb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data frame library\n",
    "import seaborn as sns # data visialization library\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6700bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart failure.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "225335cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12894ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       299 non-null    float64\n",
      " 1   anaemia                   299 non-null    int64  \n",
      " 2   creatinine_phosphokinase  299 non-null    int64  \n",
      " 3   diabetes                  299 non-null    int64  \n",
      " 4   ejection_fraction         299 non-null    int64  \n",
      " 5   high_blood_pressure       299 non-null    int64  \n",
      " 6   platelets                 299 non-null    float64\n",
      " 7   serum_creatinine          299 non-null    float64\n",
      " 8   serum_sodium              299 non-null    int64  \n",
      " 9   sex                       299 non-null    int64  \n",
      " 10  smoking                   299 non-null    int64  \n",
      " 11  time                      299 non-null    int64  \n",
      " 12  DEATH_EVENT               299 non-null    int64  \n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 30.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cf57605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({'DEATH_EVENT':'death'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d027a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>155000.00</td>\n",
       "      <td>1.1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1820</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2060</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>742000.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2413</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>140000.00</td>\n",
       "      <td>1.4</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>395000.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0    75.0        0                       582         0                 20   \n",
       "1    55.0        0                      7861         0                 38   \n",
       "2    65.0        0                       146         0                 20   \n",
       "3    50.0        1                       111         0                 20   \n",
       "4    65.0        1                       160         1                 20   \n",
       "..    ...      ...                       ...       ...                ...   \n",
       "294  62.0        0                        61         1                 38   \n",
       "295  55.0        0                      1820         0                 38   \n",
       "296  45.0        0                      2060         1                 60   \n",
       "297  45.0        0                      2413         0                 38   \n",
       "298  50.0        0                       196         0                 45   \n",
       "\n",
       "     high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                      1  265000.00               1.9           130    1   \n",
       "1                      0  263358.03               1.1           136    1   \n",
       "2                      0  162000.00               1.3           129    1   \n",
       "3                      0  210000.00               1.9           137    1   \n",
       "4                      0  327000.00               2.7           116    0   \n",
       "..                   ...        ...               ...           ...  ...   \n",
       "294                    1  155000.00               1.1           143    1   \n",
       "295                    0  270000.00               1.2           139    0   \n",
       "296                    0  742000.00               0.8           138    0   \n",
       "297                    0  140000.00               1.4           140    1   \n",
       "298                    0  395000.00               1.6           136    1   \n",
       "\n",
       "     smoking  time  death  \n",
       "0          0     4      1  \n",
       "1          0     6      1  \n",
       "2          1     7      1  \n",
       "3          0     7      1  \n",
       "4          0     8      1  \n",
       "..       ...   ...    ...  \n",
       "294        1   270      0  \n",
       "295        0   271      0  \n",
       "296        0   278      0  \n",
       "297        1   280      0  \n",
       "298        1   285      0  \n",
       "\n",
       "[299 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aff356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('new.csv') #to save/download your current csv file in your device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d505b147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    203\n",
       "1     96\n",
       "Name: death, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.death.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "429ce428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='count', ylabel='death'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y='death',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7908d227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='death', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='death',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e8afc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<AxesSubplot:xlabel='diabetes', ylabel='count'>,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='diabetes', data=df) , #='death')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e95d26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='diabetes', ylabel='count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='diabetes', data=df, hue='death')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ffbc3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    174\n",
       "1    125\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.diabetes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47bbef66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='anaemia', ylabel='count'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='anaemia', data=df, hue='death')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2cbb341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    170\n",
       "1    129\n",
       "Name: anaemia, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.anaemia.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0cb16c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='anaemia', ylabel='count'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='anaemia', data=df, hue='diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4856b9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='high_blood_pressure', ylabel='count'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='high_blood_pressure', data=df, hue='death')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "047531b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('death',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22cc8d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "479d98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bed4801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,train_size=.70,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f9e4006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281    0\n",
       "265    0\n",
       "164    1\n",
       "9      1\n",
       "77     0\n",
       "      ..\n",
       "132    0\n",
       "72     1\n",
       "15     1\n",
       "10     1\n",
       "157    0\n",
       "Name: death, Length: 90, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e7ecc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ae5f71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9018e40",
   "metadata": {},
   "source": [
    "# Apply Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1db20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc0d3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5494c820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(xtrain,ytrain) #train the model with 70% of data from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a93bdf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dt.predict(xtest) # pred is corrsponding to ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7356cc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281    0\n",
       "265    0\n",
       "164    1\n",
       "9      1\n",
       "77     0\n",
       "      ..\n",
       "132    0\n",
       "72     1\n",
       "15     1\n",
       "10     1\n",
       "157    0\n",
       "Name: death, Length: 90, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78d7c070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred # Predicted value of Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "958e56dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(ytest) # Actual Value of Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f808df94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6777777777777778"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaab2a87",
   "metadata": {},
   "source": [
    "# Evaluate the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39d5a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report , accuracy_score, confusion_matrix, plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7db85897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.69      0.83      0.75        53\\n           1       0.65      0.46      0.54        37\\n\\n    accuracy                           0.68        90\\n   macro avg       0.67      0.64      0.65        90\\nweighted avg       0.67      0.68      0.66        90\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(ytest,pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0d6aae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75        53\n",
      "           1       0.65      0.46      0.54        37\n",
      "\n",
      "    accuracy                           0.68        90\n",
      "   macro avg       0.67      0.64      0.65        90\n",
      "weighted avg       0.67      0.68      0.66        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e6fcc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_confusion_matrix = confusion_matrix(ytest,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c04aa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44,  9],\n",
       "       [20, 17]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4857990a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(test_confusion_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3095acbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fn, fp, tn = confusion_matrix(ytest,pred).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7f3ec5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6777777777777778"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e82216c",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d525dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1041b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier() # default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "500cd79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed273ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7555555555555555"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f05844",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c93ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#https://scikit-learn.org/0.16/modules/generated/sklearn.grid_search.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e13d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/datasets/toy_dataset.html\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html\n",
    "#https://scikit-learn.org/stable/datasets/real_world.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68486209",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = np.random.randint(25,200,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9301b24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([159,  85,  34,  50, 186, 151, 158, 163, 101,  47, 178,  85, 143,\n",
       "        63, 154,  44, 189,  50,  53, 187, 105,  52,  40,  84, 127])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6850cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ['gini','entropy','log_loss']\n",
    "max_depth = np.random.randint(1,15,20)\n",
    "min_samples_split = [2,3,4]\n",
    "max_features = ['sqrt', 'log2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47c168d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grids\n",
    "ids = {\n",
    "    'n_estimators' : trees,\n",
    "    'criterion' : criterion,\n",
    "    'max_depth' : max_depth,\n",
    "    'min_samples_split' : min_samples_split,\n",
    "    'max_features' : max_features\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c141bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': array([159,  85,  34,  50, 186, 151, 158, 163, 101,  47, 178,  85, 143,\n",
      "        63, 154,  44, 189,  50,  53, 187, 105,  52,  40,  84, 127]), 'criterion': ['gini', 'entropy', 'log_loss'], 'max_depth': array([ 2,  9,  4, 11,  9,  1,  5,  8, 13, 11,  4,  1,  1,  1,  2,  7,  1,\n",
      "        9,  2,  6]), 'min_samples_split': [2, 3, 4], 'max_features': ['sqrt', 'log2']}\n"
     ]
    }
   ],
   "source": [
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7e02a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e6de249",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv = RandomizedSearchCV(clf , ids, n_iter = 200, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db25b33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.86590752 0.87556936 0.83257419 0.88502415 0.77991718        nan\n",
      "        nan 0.86121463        nan 0.86597654 0.86590752 0.86597654\n",
      " 0.8515528  0.86597654 0.85148378 0.87550035 0.76563147 0.8515528\n",
      " 0.87066943 0.86121463 0.86590752 0.86590752 0.87550035 0.85645273\n",
      " 0.87080745        nan 0.86590752        nan 0.76080055 0.87556936\n",
      "        nan 0.76080055 0.80351967        nan 0.77046239        nan\n",
      "        nan        nan 0.8563147  0.85624569 0.76080055        nan\n",
      " 0.86590752 0.77508627        nan 0.84189096        nan 0.85148378\n",
      " 0.77039337        nan        nan        nan 0.86597654        nan\n",
      "        nan 0.87556936 0.86114562 0.83733609 0.87073844 0.8515528\n",
      "        nan 0.85638371 0.86597654        nan 0.88502415 0.87556936\n",
      " 0.85162181 0.76570048 0.87543133        nan 0.87550035 0.75603865\n",
      " 0.87073844        nan 0.86597654        nan 0.87550035 0.85162181\n",
      " 0.87550035 0.8563147  0.75603865 0.83243616        nan 0.87080745\n",
      " 0.85638371 0.88026225 0.84195997        nan 0.83229814 0.76556246\n",
      " 0.76080055 0.85645273        nan 0.85624569        nan 0.86114562\n",
      "        nan 0.86590752        nan 0.87073844        nan        nan\n",
      "        nan        nan 0.86597654        nan 0.76080055 0.77032436\n",
      " 0.87550035 0.87066943 0.86114562 0.84195997 0.76080055        nan\n",
      " 0.87556936 0.86114562 0.75603865 0.86597654 0.86128364 0.83719807\n",
      " 0.85162181        nan        nan        nan 0.87087647 0.86590752\n",
      "        nan        nan        nan 0.76080055 0.83740511 0.86128364\n",
      " 0.86121463 0.86121463 0.85638371 0.87543133 0.87073844        nan\n",
      " 0.76556246 0.8563147         nan 0.86583851        nan 0.85162181\n",
      "        nan 0.86597654        nan 0.87550035        nan 0.75603865\n",
      " 0.76080055        nan 0.87073844        nan        nan 0.87080745\n",
      "        nan        nan        nan 0.76570048        nan        nan\n",
      "        nan 0.86121463 0.842098          nan 0.81345756 0.83236715\n",
      "        nan 0.85638371        nan 0.85638371 0.85162181 0.76086957\n",
      " 0.88026225        nan 0.81815045 0.76086957        nan        nan\n",
      " 0.87073844 0.88033126 0.87563837 0.88026225 0.75603865 0.84189096\n",
      "        nan 0.84672188 0.84672188 0.86590752 0.76080055 0.86604555\n",
      " 0.87080745 0.75603865        nan        nan 0.75603865 0.8610766\n",
      " 0.76080055 0.87073844]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=200,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy',\n",
       "                                                      'log_loss'],\n",
       "                                        'max_depth': array([ 2,  9,  4, 11,  9,  1,  5,  8, 13, 11,  4,  1,  1,  1,  2,  7,  1,\n",
       "        9,  2,  6]),\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_split': [2, 3, 4],\n",
       "                                        'n_estimators': array([159,  85,  34,  50, 186, 151, 158, 163, 101,  47, 178,  85, 143,\n",
       "        63, 154,  44, 189,  50,  53, 187, 105,  52,  40,  84, 127])})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3fc9bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.33478491, 0.13447976, 0.40620057, 0.21878743, 0.10933248,\n",
       "        0.06770039, 0.04513844, 0.35908953, 0.0364542 , 0.11549234,\n",
       "        0.15858579, 0.21544584, 0.11457149, 0.31765532, 0.17701268,\n",
       "        0.23434901, 0.12498585, 0.33521191, 0.37492808, 0.14063009,\n",
       "        0.32828259, 0.1570224 , 0.42096027, 0.18010577, 0.08853666,\n",
       "        0.05530373, 0.41130209, 0.04163249, 0.28785006, 0.13539855,\n",
       "        0.05209541, 0.33173736, 0.09376923, 0.03644927, 0.25618641,\n",
       "        0.15293296, 0.05100671, 0.11045965, 0.10484242, 0.33850725,\n",
       "        0.19789497, 0.08852665, 0.12969589, 0.39613128, 0.05728292,\n",
       "        0.1826303 , 0.04163591, 0.14183839, 0.08332253, 0.10449243,\n",
       "        0.09506313, 0.03395844, 0.35440723, 0.15760374, 0.14352465,\n",
       "        0.19199793, 0.14218243, 0.39254371, 0.47914489, 0.31872392,\n",
       "        0.14012901, 0.42106676, 0.32367102, 0.04217132, 0.18982744,\n",
       "        0.48212242, 0.45231231, 0.08852665, 0.40666374, 0.05731217,\n",
       "        0.13807281, 0.32287828, 0.33090011, 0.04119523, 0.40833807,\n",
       "        0.10930999, 0.34992059, 0.21366445, 0.35865577, 0.10982386,\n",
       "        0.30437986, 0.20342509, 0.0781099 , 0.35518344, 0.10416142,\n",
       "        0.15625842, 0.28122131, 0.08334804, 0.12301858, 0.43815962,\n",
       "        0.35408052, 0.08335161, 0.06248156, 0.13422497, 0.12733388,\n",
       "        0.22845538, 0.06773194, 0.10986916, 0.13268415, 0.29162463,\n",
       "        0.03645253, 0.15929715, 0.12079159, 0.04136507, 0.41415111,\n",
       "        0.162275  , 0.34424535, 0.29684353, 0.46844292, 0.09897304,\n",
       "        0.11785642, 0.37541191, 0.29381347, 0.07291182, 0.14019982,\n",
       "        0.21875763, 0.37498482, 0.4738578 , 0.33332229, 0.34360361,\n",
       "        0.16683324, 0.08904592, 0.04934438, 0.08946888, 0.28002755,\n",
       "        0.40581044, 0.04282578, 0.08444778, 0.07227015, 0.19026923,\n",
       "        0.10953665, 0.08848707, 0.2293512 , 0.18002041, 0.39055761,\n",
       "        0.43786613, 0.40118853, 0.11978086, 0.19203623, 0.080151  ,\n",
       "        0.05720337, 0.1154716 , 0.06246392, 0.08484284, 0.14058701,\n",
       "        0.39670022, 0.1443154 , 0.42342679, 0.03643203, 0.35209163,\n",
       "        0.22533957, 0.03122393, 0.10101501, 0.05207745, 0.14416297,\n",
       "        0.19154986, 0.04686912, 0.06668131, 0.11596982, 0.10761007,\n",
       "        0.03124237, 0.08325402, 0.14813312, 0.28036539, 0.36662118,\n",
       "        0.04166293, 0.09858751, 0.23432994, 0.11982028, 0.2437497 ,\n",
       "        0.12837688, 0.35394231, 0.15134509, 0.38110781, 0.09894236,\n",
       "        0.10934011, 0.25299597, 0.22453125, 0.04166174, 0.10013851,\n",
       "        0.2200613 , 0.16665673, 0.20232169, 0.19355845, 0.07811872,\n",
       "        0.10939153, 0.09895341, 0.10845025, 0.16950146, 0.24316223,\n",
       "        0.47304964, 0.13968881, 0.13147712, 0.37916549, 0.04166118,\n",
       "        0.15954296, 0.40452059, 0.40094535, 0.34895054, 0.1041317 ]),\n",
       " 'std_fit_time': array([2.00169470e-02, 3.03715973e-02, 3.36946691e-02, 3.37239497e-02,\n",
       "        1.27572543e-02, 7.36474045e-03, 1.26286711e-02, 6.61172045e-02,\n",
       "        7.41489728e-03, 1.34640810e-02, 4.83519163e-02, 2.92187665e-02,\n",
       "        7.36410198e-03, 7.37897369e-03, 7.40773067e-03, 3.37544581e-02,\n",
       "        1.27214920e-02, 9.37620565e-03, 3.37978507e-02, 3.37362965e-02,\n",
       "        2.52474788e-02, 1.05854719e-02, 4.94789677e-02, 1.24243837e-02,\n",
       "        1.95080838e-02, 6.43838614e-03, 1.46473776e-02, 1.47535764e-02,\n",
       "        6.59167065e-03, 1.47892481e-02, 7.40756330e-03, 8.60675089e-03,\n",
       "        2.20236399e-02, 7.41281759e-03, 4.59278782e-02, 2.01498454e-02,\n",
       "        1.47398807e-02, 1.12497850e-02, 2.21581303e-02, 1.47354955e-02,\n",
       "        3.89687806e-02, 7.31806515e-03, 1.53797543e-02, 3.20937232e-02,\n",
       "        1.47316728e-02, 3.73496992e-02, 1.47486234e-02, 2.32255494e-02,\n",
       "        7.30766859e-03, 1.44444921e-02, 1.05111864e-02, 9.60690456e-03,\n",
       "        1.71759707e-02, 2.39190004e-02, 3.02984814e-03, 2.53351865e-02,\n",
       "        2.35438132e-02, 5.65127206e-02, 6.42004123e-02, 1.31887993e-02,\n",
       "        2.18243655e-02, 3.48132273e-02, 1.95549085e-02, 7.80182753e-03,\n",
       "        1.00202035e-02, 3.11178617e-03, 4.36608853e-02, 1.47298760e-02,\n",
       "        6.40385567e-04, 7.38346760e-03, 9.52017872e-03, 3.89692258e-02,\n",
       "        3.48844698e-02, 7.09470208e-03, 3.58043412e-02, 3.20087240e-05,\n",
       "        3.00316240e-02, 7.33804802e-02, 3.31344351e-02, 5.96295633e-04,\n",
       "        2.44596004e-02, 2.55143195e-02, 2.65729483e-06, 5.89744206e-03,\n",
       "        1.94883725e-02, 3.37754224e-02, 2.20889386e-02, 1.95183448e-02,\n",
       "        1.59287475e-02, 3.43392581e-02, 7.37849062e-03, 7.34641129e-03,\n",
       "        4.00492751e-05, 9.33945265e-03, 1.45034879e-02, 3.70651187e-02,\n",
       "        7.37583505e-03, 6.83604354e-04, 6.74229350e-03, 2.57697080e-02,\n",
       "        7.36608924e-03, 3.37795420e-02, 2.48194821e-02, 4.04797748e-03,\n",
       "        4.04592880e-02, 1.74120971e-02, 4.37672680e-02, 3.38010532e-02,\n",
       "        3.39355099e-02, 7.34625887e-03, 6.45047028e-03, 4.55406678e-02,\n",
       "        3.45942169e-02, 1.47272334e-02, 5.68060815e-03, 1.27206929e-02,\n",
       "        1.27532381e-02, 6.42263572e-02, 7.35652577e-03, 3.30946316e-02,\n",
       "        2.05502973e-03, 3.46869111e-02, 2.73283902e-03, 2.26792614e-02,\n",
       "        4.84984734e-02, 2.97772125e-02, 8.32131273e-03, 1.46291507e-02,\n",
       "        1.58928377e-02, 3.30103111e-02, 2.55197215e-04, 7.31867653e-03,\n",
       "        7.51123916e-03, 6.36673458e-03, 1.27871735e-02, 7.09336877e-02,\n",
       "        3.18741585e-02, 7.36648304e-03, 1.78456500e-02, 2.51428455e-03,\n",
       "        4.19233954e-03, 8.90489063e-03, 1.27935898e-02, 1.78186356e-02,\n",
       "        2.55401480e-02, 2.69479468e-02, 3.60146973e-02, 2.68247809e-02,\n",
       "        7.33574351e-03, 2.37730481e-02, 1.95376828e-02, 3.52957929e-05,\n",
       "        1.04749155e-02, 1.95471092e-02, 1.17349591e-02, 1.04207525e-02,\n",
       "        6.75838059e-05, 5.97655208e-03, 2.89417142e-02, 1.96069950e-02,\n",
       "        5.70546503e-06, 2.23032670e-02, 1.14077260e-02, 3.96719740e-02,\n",
       "        2.76810280e-02, 1.47308293e-02, 1.85747028e-02, 4.06306113e-05,\n",
       "        1.46993632e-02, 2.91027435e-02, 1.36097606e-02, 1.93257531e-02,\n",
       "        2.90078776e-02, 8.84309987e-02, 7.37783868e-03, 2.21118462e-02,\n",
       "        4.02576792e-03, 2.43925000e-02, 7.36389737e-03, 4.56442664e-03,\n",
       "        2.71369227e-02, 7.42109962e-03, 1.06955351e-03, 1.92484825e-02,\n",
       "        1.26843694e-02, 2.20781590e-02, 7.37558770e-03, 2.36667874e-02,\n",
       "        1.78114813e-03, 4.76557895e-02, 1.37089556e-02, 1.29915002e-02,\n",
       "        1.39568000e-02, 3.92754055e-02, 1.47307171e-02, 2.34634509e-03,\n",
       "        4.76865221e-02, 1.94901946e-02, 2.94377973e-02, 7.40267268e-03]),\n",
       " 'mean_score_time': array([0.03703022, 0.013086  , 0.03646032, 0.02610262, 0.0052077 ,\n",
       "        0.        , 0.        , 0.03648265, 0.        , 0.01453161,\n",
       "        0.01559043, 0.02085845, 0.01041373, 0.02603491, 0.0260756 ,\n",
       "        0.01564097, 0.01562007, 0.02603412, 0.03130198, 0.01039735,\n",
       "        0.02134633, 0.0165054 , 0.02520831, 0.01890341, 0.01041754,\n",
       "        0.        , 0.03645547, 0.        , 0.0166831 , 0.01041611,\n",
       "        0.        , 0.03125024, 0.0104142 , 0.        , 0.01569645,\n",
       "        0.        , 0.        , 0.        , 0.01574636, 0.02083182,\n",
       "        0.01562413, 0.        , 0.01043804, 0.0208346 , 0.        ,\n",
       "        0.01039791, 0.        , 0.01317692, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0312465 , 0.        , 0.        ,\n",
       "        0.01539103, 0.01484156, 0.03127456, 0.04165649, 0.03648384,\n",
       "        0.        , 0.0312225 , 0.03644721, 0.        , 0.01310166,\n",
       "        0.04240417, 0.04689765, 0.01563096, 0.03124245, 0.        ,\n",
       "        0.01390505, 0.02601226, 0.03126216, 0.        , 0.03124841,\n",
       "        0.        , 0.03122203, 0.01041873, 0.03648225, 0.01038782,\n",
       "        0.02083071, 0.01562436, 0.        , 0.02602752, 0.01562023,\n",
       "        0.01559742, 0.02603563, 0.        , 0.00523265, 0.03647574,\n",
       "        0.02606122, 0.01561197, 0.        , 0.00666658, 0.        ,\n",
       "        0.01599065, 0.        , 0.01262132, 0.        , 0.02009193,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.03518526,\n",
       "        0.        , 0.02085169, 0.02083103, 0.02777735, 0.00518131,\n",
       "        0.00789674, 0.03124396, 0.0300734 , 0.        , 0.01559035,\n",
       "        0.02080146, 0.02603451, 0.03648567, 0.02082864, 0.01856446,\n",
       "        0.01483456, 0.        , 0.        , 0.        , 0.01564161,\n",
       "        0.03077888, 0.        , 0.        , 0.        , 0.01559663,\n",
       "        0.01045394, 0.01574477, 0.01562087, 0.010415  , 0.03645356,\n",
       "        0.03124364, 0.03123816, 0.        , 0.01222761, 0.01041587,\n",
       "        0.        , 0.01042811, 0.        , 0.01307336, 0.        ,\n",
       "        0.03124158, 0.        , 0.03126995, 0.        , 0.03124889,\n",
       "        0.02082634, 0.        , 0.01041579, 0.        , 0.        ,\n",
       "        0.01562381, 0.        , 0.        , 0.        , 0.013153  ,\n",
       "        0.        , 0.        , 0.        , 0.02882965, 0.03122322,\n",
       "        0.        , 0.01054295, 0.01589759, 0.        , 0.01843882,\n",
       "        0.        , 0.03124666, 0.01041349, 0.03124698, 0.00521278,\n",
       "        0.        , 0.01574874, 0.0187362 , 0.        , 0.        ,\n",
       "        0.01562206, 0.01561586, 0.01563756, 0.02083484, 0.01041341,\n",
       "        0.01041269, 0.        , 0.01101398, 0.0145247 , 0.02514585,\n",
       "        0.03994942, 0.01400534, 0.01033338, 0.03368934, 0.        ,\n",
       "        0.        , 0.03789226, 0.03647772, 0.03124317, 0.00520658]),\n",
       " 'std_score_time': array([8.12750396e-03, 3.58866368e-03, 7.36108851e-03, 7.40034762e-03,\n",
       "        7.36479650e-03, 0.00000000e+00, 0.00000000e+00, 1.47498073e-02,\n",
       "        0.00000000e+00, 1.54915250e-03, 4.05792811e-05, 7.34868839e-03,\n",
       "        7.36361709e-03, 7.36209985e-03, 7.39208391e-03, 2.43046664e-05,\n",
       "        4.94906027e-06, 1.47907341e-02, 1.27860103e-02, 7.35211944e-03,\n",
       "        8.09438658e-03, 7.10026736e-06, 9.70077797e-03, 4.65256969e-03,\n",
       "        7.36631402e-03, 0.00000000e+00, 7.36856196e-03, 0.00000000e+00,\n",
       "        1.50262209e-03, 7.36530255e-03, 0.00000000e+00, 6.69963278e-05,\n",
       "        7.36395455e-03, 0.00000000e+00, 8.43369192e-05, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.92514994e-04, 7.36524608e-03,\n",
       "        1.25153985e-06, 0.00000000e+00, 7.38086444e-03, 7.36227350e-03,\n",
       "        0.00000000e+00, 7.35245161e-03, 0.00000000e+00, 1.32648234e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        9.60274217e-07, 0.00000000e+00, 0.00000000e+00, 3.24150515e-04,\n",
       "        2.44079649e-03, 3.98037658e-05, 7.35917724e-03, 7.40750533e-03,\n",
       "        0.00000000e+00, 3.28275824e-05, 7.36952107e-03, 0.00000000e+00,\n",
       "        3.56601686e-03, 7.94144444e-03, 7.45613845e-05, 1.03008599e-06,\n",
       "        6.18766520e-06, 0.00000000e+00, 2.40950391e-03, 7.34651408e-03,\n",
       "        1.90774596e-05, 0.00000000e+00, 6.12249544e-05, 0.00000000e+00,\n",
       "        1.27575208e-02, 7.36715673e-03, 7.40272885e-03, 7.34539018e-03,\n",
       "        7.37024784e-03, 1.27565911e-02, 0.00000000e+00, 7.35318462e-03,\n",
       "        6.50319180e-06, 3.51710281e-05, 7.36311166e-03, 0.00000000e+00,\n",
       "        7.40008747e-03, 7.34923844e-03, 7.38075059e-03, 1.69174554e-05,\n",
       "        0.00000000e+00, 4.71398453e-03, 0.00000000e+00, 5.21497914e-04,\n",
       "        0.00000000e+00, 4.69727946e-03, 0.00000000e+00, 6.05772435e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.43680358e-03, 0.00000000e+00, 7.39435552e-03, 7.36698817e-03,\n",
       "        4.91055742e-03, 7.32748249e-03, 6.37952117e-03, 1.27873620e-02,\n",
       "        1.65889997e-03, 0.00000000e+00, 4.08535335e-05, 7.32146973e-03,\n",
       "        7.36249390e-03, 7.35367827e-03, 7.35940180e-03, 3.84765449e-03,\n",
       "        2.36472239e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.21079678e-02, 1.28626279e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.70045519e-05, 7.39219242e-03, 1.33433535e-04,\n",
       "        4.32817103e-06, 7.36451556e-03, 7.36350411e-03, 3.14696469e-06,\n",
       "        9.60274217e-07, 0.00000000e+00, 8.92685146e-03, 7.36513368e-03,\n",
       "        0.00000000e+00, 7.37379561e-03, 0.00000000e+00, 3.57669618e-03,\n",
       "        0.00000000e+00, 4.70973091e-06, 0.00000000e+00, 3.11105541e-05,\n",
       "        0.00000000e+00, 8.67165078e-06, 7.31945824e-03, 0.00000000e+00,\n",
       "        1.47301550e-02, 0.00000000e+00, 0.00000000e+00, 1.66324373e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.49408613e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.41816581e-03,\n",
       "        3.84853836e-05, 0.00000000e+00, 7.45662740e-03, 3.89245005e-04,\n",
       "        0.00000000e+00, 3.98726066e-03, 0.00000000e+00, 1.27562018e-02,\n",
       "        7.36344801e-03, 5.67327127e-06, 7.37198957e-03, 0.00000000e+00,\n",
       "        1.77692073e-04, 4.40766261e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.56260048e-06, 6.20906353e-06, 3.46160642e-05, 7.37187718e-03,\n",
       "        7.36339208e-03, 7.36288597e-03, 0.00000000e+00, 3.26033391e-03,\n",
       "        2.77413788e-05, 5.41945729e-03, 3.85843669e-03, 1.78342858e-03,\n",
       "        2.35572866e-04, 1.32363601e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.56849275e-03, 7.39986281e-03, 3.27096234e-06, 7.36322302e-03]),\n",
       " 'param_n_estimators': masked_array(data=[143, 50, 187, 85, 50, 53, 50, 163, 44, 53, 63, 101, 40,\n",
       "                    159, 85, 84, 52, 159, 163, 52, 154, 50, 143, 85, 34,\n",
       "                    85, 186, 47, 151, 52, 85, 154, 40, 47, 127, 186, 85,\n",
       "                    158, 53, 154, 85, 143, 50, 186, 50, 85, 47, 63, 34,\n",
       "                    127, 163, 53, 163, 178, 186, 85, 52, 178, 186, 158,\n",
       "                    178, 186, 154, 34, 85, 186, 187, 47, 186, 50, 50, 143,\n",
       "                    151, 40, 187, 178, 158, 85, 159, 52, 151, 84, 127, 158,\n",
       "                    53, 85, 127, 105, 44, 178, 154, 44, 85, 50, 159, 101,\n",
       "                    85, 47, 187, 127, 50, 189, 158, 50, 163, 154, 158, 127,\n",
       "                    186, 40, 53, 163, 151, 85, 52, 85, 158, 189, 163, 154,\n",
       "                    85, 163, 50, 85, 105, 189, 52, 84, 84, 85, 53, 47, 101,\n",
       "                    85, 178, 187, 187, 158, 85, 40, 105, 44, 63, 34, 178,\n",
       "                    186, 187, 186, 52, 189, 101, 50, 50, 50, 186, 84, 52,\n",
       "                    84, 151, 50, 40, 101, 178, 105, 154, 40, 44, 127, 163,\n",
       "                    105, 186, 159, 52, 163, 47, 159, 101, 101, 52, 151,\n",
       "                    101, 84, 101, 85, 34, 47, 154, 44, 85, 105, 189, 47,\n",
       "                    53, 151, 52, 158, 189, 186, 186, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[4, 2, 4, 4, 3, 2, 4, 2, 4, 2, 3, 3, 2, 2, 3, 2, 4, 3,\n",
       "                    3, 4, 2, 2, 2, 3, 2, 2, 4, 4, 2, 4, 3, 3, 3, 4, 2, 4,\n",
       "                    4, 4, 2, 3, 4, 4, 4, 3, 2, 2, 2, 2, 2, 2, 3, 3, 4, 2,\n",
       "                    2, 4, 3, 2, 4, 3, 3, 3, 2, 3, 3, 4, 2, 4, 2, 4, 4, 4,\n",
       "                    3, 3, 3, 2, 3, 2, 3, 2, 2, 3, 4, 3, 3, 3, 2, 2, 4, 2,\n",
       "                    4, 2, 4, 3, 3, 4, 4, 2, 3, 2, 4, 2, 4, 3, 4, 3, 4, 3,\n",
       "                    3, 3, 3, 3, 2, 3, 4, 3, 4, 4, 3, 2, 2, 4, 3, 4, 2, 2,\n",
       "                    2, 3, 2, 3, 2, 3, 3, 2, 4, 4, 4, 2, 2, 2, 4, 4, 2, 4,\n",
       "                    2, 4, 3, 2, 4, 2, 3, 3, 4, 4, 4, 3, 3, 2, 4, 3, 2, 3,\n",
       "                    4, 4, 2, 2, 4, 4, 3, 3, 3, 3, 4, 4, 2, 4, 3, 3, 2, 2,\n",
       "                    2, 4, 3, 4, 3, 4, 4, 2, 2, 3, 2, 3, 3, 2, 3, 4, 2, 2,\n",
       "                    4, 2],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['sqrt', 'log2', 'log2', 'sqrt', 'log2', 'log2', 'sqrt',\n",
       "                    'sqrt', 'log2', 'sqrt', 'sqrt', 'log2', 'sqrt', 'log2',\n",
       "                    'sqrt', 'sqrt', 'log2', 'sqrt', 'sqrt', 'log2', 'log2',\n",
       "                    'log2', 'sqrt', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'log2',\n",
       "                    'sqrt', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'log2', 'sqrt', 'log2', 'log2', 'sqrt', 'log2',\n",
       "                    'sqrt', 'log2', 'sqrt', 'log2', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'log2', 'log2', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'log2', 'sqrt', 'log2', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'log2', 'log2', 'log2', 'sqrt', 'log2', 'sqrt',\n",
       "                    'log2', 'log2', 'sqrt', 'log2', 'sqrt', 'log2', 'sqrt',\n",
       "                    'log2', 'log2', 'log2', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'sqrt', 'sqrt',\n",
       "                    'log2', 'sqrt', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'sqrt', 'sqrt', 'log2', 'log2', 'sqrt',\n",
       "                    'log2', 'sqrt', 'log2', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'sqrt', 'log2',\n",
       "                    'log2', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'log2', 'sqrt', 'log2', 'log2', 'sqrt',\n",
       "                    'sqrt', 'log2', 'sqrt', 'sqrt'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[11, 5, 2, 6, 1, 13, 4, 2, 1, 9, 9, 4, 11, 11, 9, 7, 1,\n",
       "                    2, 7, 13, 4, 13, 4, 7, 4, 1, 9, 5, 1, 9, 7, 1, 1, 6, 1,\n",
       "                    2, 11, 6, 9, 2, 1, 1, 11, 1, 2, 2, 11, 5, 1, 2, 4, 11,\n",
       "                    9, 1, 4, 4, 13, 2, 11, 2, 9, 4, 4, 6, 11, 9, 2, 1, 9,\n",
       "                    13, 5, 1, 5, 5, 6, 1, 9, 4, 8, 9, 1, 2, 7, 9, 9, 7, 2,\n",
       "                    4, 2, 1, 1, 9, 11, 9, 1, 5, 4, 9, 1, 7, 1, 6, 1, 11, 9,\n",
       "                    4, 1, 1, 11, 9, 5, 2, 1, 1, 9, 9, 1, 4, 4, 2, 9, 9, 6,\n",
       "                    9, 11, 9, 1, 11, 1, 1, 2, 13, 9, 7, 4, 4, 11, 2, 1, 9,\n",
       "                    1, 9, 2, 6, 9, 11, 7, 11, 1, 1, 1, 1, 9, 9, 13, 11, 9,\n",
       "                    13, 1, 1, 7, 1, 9, 6, 2, 8, 2, 2, 5, 11, 2, 9, 8, 1,\n",
       "                    11, 13, 2, 1, 2, 2, 13, 11, 4, 9, 1, 2, 1, 4, 7, 5, 1,\n",
       "                    5, 13, 1, 9, 4, 1, 2, 1, 8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_criterion': masked_array(data=['entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'log_loss', 'log_loss', 'gini', 'log_loss', 'entropy',\n",
       "                    'entropy', 'gini', 'entropy', 'gini', 'gini',\n",
       "                    'entropy', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'gini', 'gini',\n",
       "                    'log_loss', 'entropy', 'log_loss', 'entropy',\n",
       "                    'entropy', 'log_loss', 'entropy', 'gini', 'log_loss',\n",
       "                    'gini', 'log_loss', 'log_loss', 'log_loss', 'gini',\n",
       "                    'gini', 'gini', 'log_loss', 'entropy', 'entropy',\n",
       "                    'log_loss', 'entropy', 'log_loss', 'entropy',\n",
       "                    'entropy', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'entropy', 'log_loss', 'log_loss', 'gini', 'entropy',\n",
       "                    'gini', 'entropy', 'entropy', 'log_loss', 'gini',\n",
       "                    'gini', 'log_loss', 'entropy', 'gini', 'entropy',\n",
       "                    'gini', 'entropy', 'log_loss', 'entropy', 'gini',\n",
       "                    'entropy', 'log_loss', 'gini', 'log_loss', 'entropy',\n",
       "                    'entropy', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'log_loss', 'gini', 'gini', 'gini', 'gini', 'log_loss',\n",
       "                    'entropy', 'gini', 'gini', 'gini', 'log_loss',\n",
       "                    'entropy', 'log_loss', 'gini', 'log_loss', 'entropy',\n",
       "                    'log_loss', 'entropy', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'gini', 'log_loss', 'entropy',\n",
       "                    'entropy', 'gini', 'entropy', 'entropy', 'entropy',\n",
       "                    'gini', 'log_loss', 'gini', 'entropy', 'gini',\n",
       "                    'entropy', 'gini', 'gini', 'gini', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'entropy', 'gini', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'entropy', 'entropy', 'gini',\n",
       "                    'entropy', 'entropy', 'gini', 'entropy', 'gini',\n",
       "                    'log_loss', 'entropy', 'entropy', 'log_loss',\n",
       "                    'entropy', 'log_loss', 'gini', 'log_loss', 'gini',\n",
       "                    'log_loss', 'gini', 'log_loss', 'gini', 'entropy',\n",
       "                    'log_loss', 'entropy', 'log_loss', 'log_loss', 'gini',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'entropy',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'entropy',\n",
       "                    'entropy', 'log_loss', 'entropy', 'gini', 'log_loss',\n",
       "                    'entropy', 'log_loss', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'log_loss', 'entropy', 'entropy',\n",
       "                    'log_loss', 'log_loss', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'gini', 'gini', 'log_loss', 'entropy',\n",
       "                    'entropy', 'gini', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'log_loss', 'log_loss', 'entropy',\n",
       "                    'entropy', 'gini', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 143,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 5,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 187,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 6,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 53,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 13,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 163,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 44,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 53,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 63,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 101,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 40,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 159,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 84,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 52,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 159,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 163,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 52,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 13,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 154,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 13,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 143,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 34,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 47,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 5,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 151,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 52,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 154,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 40,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 47,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 6,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 127,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 158,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 6,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 53,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 154,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 143,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 47,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 63,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 5,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 34,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 127,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 163,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 53,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 163,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 178,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 52,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 13,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 178,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 158,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 178,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 154,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 34,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 6,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 187,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 47,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 13,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 5,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 143,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 151,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 5,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 40,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 5,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 187,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 6,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 178,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 158,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 159,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 8,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 52,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 151,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 84,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 127,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 158,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 53,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 127,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 105,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 44,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 178,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 154,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 44,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 159,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 101,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 5,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 47,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 187,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 127,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 189,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 6,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 158,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 163,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 154,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 158,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 127,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 40,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 53,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 5,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 163,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 151,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 52,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 158,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 189,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 163,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 154,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 163,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 6,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 105,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 189,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 52,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 84,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 84,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 53,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 47,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 13,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 101,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 178,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 187,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 187,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 158,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 40,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 105,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 44,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 63,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 34,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 6,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 178,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 187,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 52,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 189,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 101,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 13,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 84,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 52,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 84,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 13,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 151,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 40,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 101,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 178,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 105,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 6,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 154,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 40,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 8,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 44,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 127,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 163,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 5,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 105,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 159,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 52,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 8,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 163,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 47,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 159,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 13,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 101,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 101,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 52,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 151,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 101,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 13,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 84,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 11,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 101,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 34,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 47,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 154,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 44,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 105,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 5,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 189,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 47,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 5,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 53,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 13,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 151,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 52,\n",
       "   'min_samples_split': 3,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 9,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 158,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 4,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 189,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 2,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 186,\n",
       "   'min_samples_split': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 8,\n",
       "   'criterion': 'entropy'}],\n",
       " 'split0_test_score': array([0.81428571, 0.8       , 0.78571429, 0.85714286, 0.72857143,\n",
       "               nan,        nan, 0.77142857,        nan, 0.78571429,\n",
       "        0.84285714, 0.81428571, 0.81428571, 0.81428571, 0.81428571,\n",
       "        0.82857143, 0.74285714, 0.78571429, 0.82857143, 0.81428571,\n",
       "        0.8       , 0.81428571, 0.81428571, 0.77142857, 0.81428571,\n",
       "               nan, 0.81428571,        nan, 0.74285714, 0.82857143,\n",
       "               nan, 0.74285714, 0.75714286,        nan, 0.75714286,\n",
       "               nan,        nan,        nan, 0.81428571, 0.82857143,\n",
       "        0.74285714,        nan, 0.8       , 0.72857143,        nan,\n",
       "        0.81428571,        nan, 0.81428571, 0.75714286,        nan,\n",
       "               nan,        nan, 0.81428571,        nan,        nan,\n",
       "        0.8       , 0.82857143, 0.78571429, 0.82857143, 0.81428571,\n",
       "               nan, 0.78571429, 0.81428571,        nan, 0.84285714,\n",
       "        0.81428571, 0.78571429, 0.72857143, 0.84285714,        nan,\n",
       "        0.82857143, 0.74285714, 0.8       ,        nan, 0.8       ,\n",
       "               nan, 0.82857143, 0.78571429, 0.81428571, 0.82857143,\n",
       "        0.74285714, 0.78571429,        nan, 0.81428571, 0.8       ,\n",
       "        0.82857143, 0.81428571,        nan, 0.8       , 0.77142857,\n",
       "        0.74285714, 0.8       ,        nan, 0.82857143,        nan,\n",
       "        0.8       ,        nan, 0.8       ,        nan, 0.82857143,\n",
       "               nan,        nan,        nan,        nan, 0.81428571,\n",
       "               nan, 0.75714286, 0.75714286, 0.82857143, 0.81428571,\n",
       "        0.82857143, 0.8       , 0.75714286,        nan, 0.82857143,\n",
       "        0.81428571, 0.74285714, 0.78571429, 0.78571429, 0.82857143,\n",
       "        0.78571429,        nan,        nan,        nan, 0.81428571,\n",
       "        0.82857143,        nan,        nan,        nan, 0.75714286,\n",
       "        0.8       , 0.8       , 0.8       , 0.8       , 0.78571429,\n",
       "        0.84285714, 0.82857143,        nan, 0.74285714, 0.81428571,\n",
       "               nan, 0.81428571,        nan, 0.82857143,        nan,\n",
       "        0.81428571,        nan, 0.82857143,        nan, 0.72857143,\n",
       "        0.74285714,        nan, 0.84285714,        nan,        nan,\n",
       "        0.81428571,        nan,        nan,        nan, 0.74285714,\n",
       "               nan,        nan,        nan, 0.78571429, 0.82857143,\n",
       "               nan, 0.81428571, 0.82857143,        nan, 0.8       ,\n",
       "               nan, 0.8       , 0.8       , 0.72857143, 0.82857143,\n",
       "               nan, 0.78571429, 0.74285714,        nan,        nan,\n",
       "        0.82857143, 0.82857143, 0.8       , 0.84285714, 0.74285714,\n",
       "        0.81428571,        nan, 0.8       , 0.78571429, 0.82857143,\n",
       "        0.75714286, 0.8       , 0.81428571, 0.74285714,        nan,\n",
       "               nan, 0.74285714, 0.81428571, 0.75714286, 0.82857143]),\n",
       " 'split1_test_score': array([0.94285714, 0.95714286, 0.87142857, 0.94285714, 0.82857143,\n",
       "               nan,        nan, 0.95714286,        nan, 0.95714286,\n",
       "        0.91428571, 0.92857143, 0.91428571, 0.92857143, 0.92857143,\n",
       "        0.94285714, 0.77142857, 0.94285714, 0.94285714, 0.91428571,\n",
       "        0.95714286, 0.94285714, 0.95714286, 0.94285714, 0.92857143,\n",
       "               nan, 0.94285714,        nan, 0.77142857, 0.92857143,\n",
       "               nan, 0.77142857, 0.91428571,        nan, 0.75714286,\n",
       "               nan,        nan,        nan, 0.92857143, 0.92857143,\n",
       "        0.77142857,        nan, 0.95714286, 0.82857143,        nan,\n",
       "        0.91428571,        nan, 0.92857143, 0.77142857,        nan,\n",
       "               nan,        nan, 0.92857143,        nan,        nan,\n",
       "        0.95714286, 0.91428571, 0.88571429, 0.92857143, 0.91428571,\n",
       "               nan, 0.94285714, 0.92857143,        nan, 0.95714286,\n",
       "        0.94285714, 0.92857143, 0.77142857, 0.94285714,        nan,\n",
       "        0.94285714, 0.75714286, 0.95714286,        nan, 0.94285714,\n",
       "               nan, 0.94285714, 0.92857143, 0.95714286, 0.91428571,\n",
       "        0.75714286, 0.9       ,        nan, 0.92857143, 0.92857143,\n",
       "        0.95714286, 0.9       ,        nan, 0.91428571, 0.75714286,\n",
       "        0.77142857, 0.91428571,        nan, 0.92857143,        nan,\n",
       "        0.94285714,        nan, 0.95714286,        nan, 0.92857143,\n",
       "               nan,        nan,        nan,        nan, 0.92857143,\n",
       "               nan, 0.75714286, 0.78571429, 0.94285714, 0.95714286,\n",
       "        0.91428571, 0.91428571, 0.75714286,        nan, 0.92857143,\n",
       "        0.92857143, 0.75714286, 0.95714286, 0.92857143, 0.87142857,\n",
       "        0.92857143,        nan,        nan,        nan, 0.91428571,\n",
       "        0.92857143,        nan,        nan,        nan, 0.75714286,\n",
       "        0.85714286, 0.91428571, 0.92857143, 0.92857143, 0.94285714,\n",
       "        0.94285714, 0.92857143,        nan, 0.78571429, 0.92857143,\n",
       "               nan, 0.95714286,        nan, 0.88571429,        nan,\n",
       "        0.92857143,        nan, 0.94285714,        nan, 0.77142857,\n",
       "        0.77142857,        nan, 0.91428571,        nan,        nan,\n",
       "        0.92857143,        nan,        nan,        nan, 0.75714286,\n",
       "               nan,        nan,        nan, 0.94285714, 0.85714286,\n",
       "               nan, 0.8       , 0.87142857,        nan, 0.92857143,\n",
       "               nan, 0.92857143, 0.91428571, 0.77142857, 0.95714286,\n",
       "               nan, 0.85714286, 0.75714286,        nan,        nan,\n",
       "        0.92857143, 0.94285714, 0.94285714, 0.94285714, 0.75714286,\n",
       "        0.91428571,        nan, 0.92857143, 0.94285714, 0.92857143,\n",
       "        0.75714286, 0.92857143, 0.92857143, 0.75714286,        nan,\n",
       "               nan, 0.75714286, 0.94285714, 0.75714286, 0.92857143]),\n",
       " 'split2_test_score': array([0.84057971, 0.86956522, 0.84057971, 0.85507246, 0.7826087 ,\n",
       "               nan,        nan, 0.85507246,        nan, 0.85507246,\n",
       "        0.84057971, 0.85507246, 0.82608696, 0.85507246, 0.8115942 ,\n",
       "        0.85507246, 0.7826087 , 0.82608696, 0.84057971, 0.85507246,\n",
       "        0.84057971, 0.84057971, 0.85507246, 0.85507246, 0.86956522,\n",
       "               nan, 0.84057971,        nan, 0.76811594, 0.86956522,\n",
       "               nan, 0.76811594, 0.73913043,        nan, 0.79710145,\n",
       "               nan,        nan,        nan, 0.82608696, 0.8115942 ,\n",
       "        0.76811594,        nan, 0.84057971, 0.76811594,        nan,\n",
       "        0.79710145,        nan, 0.8115942 , 0.7826087 ,        nan,\n",
       "               nan,        nan, 0.85507246,        nan,        nan,\n",
       "        0.86956522, 0.84057971, 0.84057971, 0.85507246, 0.82608696,\n",
       "               nan, 0.84057971, 0.85507246,        nan, 0.85507246,\n",
       "        0.86956522, 0.84057971, 0.79710145, 0.84057971,        nan,\n",
       "        0.85507246, 0.76811594, 0.85507246,        nan, 0.85507246,\n",
       "               nan, 0.85507246, 0.84057971, 0.85507246, 0.82608696,\n",
       "        0.76811594, 0.8115942 ,        nan, 0.86956522, 0.84057971,\n",
       "        0.85507246, 0.8115942 ,        nan, 0.7826087 , 0.76811594,\n",
       "        0.76811594, 0.85507246,        nan, 0.8115942 ,        nan,\n",
       "        0.84057971,        nan, 0.84057971,        nan, 0.85507246,\n",
       "               nan,        nan,        nan,        nan, 0.85507246,\n",
       "               nan, 0.76811594, 0.76811594, 0.85507246, 0.84057971,\n",
       "        0.84057971, 0.8115942 , 0.76811594,        nan, 0.86956522,\n",
       "        0.84057971, 0.76811594, 0.85507246, 0.86956522, 0.8115942 ,\n",
       "        0.84057971,        nan,        nan,        nan, 0.88405797,\n",
       "        0.84057971,        nan,        nan,        nan, 0.76811594,\n",
       "        0.85507246, 0.86956522, 0.85507246, 0.85507246, 0.84057971,\n",
       "        0.84057971, 0.85507246,        nan, 0.76811594, 0.82608696,\n",
       "               nan, 0.82608696,        nan, 0.84057971,        nan,\n",
       "        0.85507246,        nan, 0.85507246,        nan, 0.76811594,\n",
       "        0.76811594,        nan, 0.85507246,        nan,        nan,\n",
       "        0.86956522,        nan,        nan,        nan, 0.79710145,\n",
       "               nan,        nan,        nan, 0.85507246, 0.84057971,\n",
       "               nan, 0.82608696, 0.79710145,        nan, 0.84057971,\n",
       "               nan, 0.84057971, 0.84057971, 0.7826087 , 0.85507246,\n",
       "               nan, 0.8115942 , 0.7826087 ,        nan,        nan,\n",
       "        0.85507246, 0.86956522, 0.88405797, 0.85507246, 0.76811594,\n",
       "        0.79710145,        nan, 0.8115942 , 0.8115942 , 0.84057971,\n",
       "        0.76811594, 0.86956522, 0.86956522, 0.76811594,        nan,\n",
       "               nan, 0.76811594, 0.82608696, 0.76811594, 0.85507246]),\n",
       " 'mean_test_score': array([0.86590752, 0.87556936, 0.83257419, 0.88502415, 0.77991718,\n",
       "               nan,        nan, 0.86121463,        nan, 0.86597654,\n",
       "        0.86590752, 0.86597654, 0.8515528 , 0.86597654, 0.85148378,\n",
       "        0.87550035, 0.76563147, 0.8515528 , 0.87066943, 0.86121463,\n",
       "        0.86590752, 0.86590752, 0.87550035, 0.85645273, 0.87080745,\n",
       "               nan, 0.86590752,        nan, 0.76080055, 0.87556936,\n",
       "               nan, 0.76080055, 0.80351967,        nan, 0.77046239,\n",
       "               nan,        nan,        nan, 0.8563147 , 0.85624569,\n",
       "        0.76080055,        nan, 0.86590752, 0.77508627,        nan,\n",
       "        0.84189096,        nan, 0.85148378, 0.77039337,        nan,\n",
       "               nan,        nan, 0.86597654,        nan,        nan,\n",
       "        0.87556936, 0.86114562, 0.83733609, 0.87073844, 0.8515528 ,\n",
       "               nan, 0.85638371, 0.86597654,        nan, 0.88502415,\n",
       "        0.87556936, 0.85162181, 0.76570048, 0.87543133,        nan,\n",
       "        0.87550035, 0.75603865, 0.87073844,        nan, 0.86597654,\n",
       "               nan, 0.87550035, 0.85162181, 0.87550035, 0.8563147 ,\n",
       "        0.75603865, 0.83243616,        nan, 0.87080745, 0.85638371,\n",
       "        0.88026225, 0.84195997,        nan, 0.83229814, 0.76556246,\n",
       "        0.76080055, 0.85645273,        nan, 0.85624569,        nan,\n",
       "        0.86114562,        nan, 0.86590752,        nan, 0.87073844,\n",
       "               nan,        nan,        nan,        nan, 0.86597654,\n",
       "               nan, 0.76080055, 0.77032436, 0.87550035, 0.87066943,\n",
       "        0.86114562, 0.84195997, 0.76080055,        nan, 0.87556936,\n",
       "        0.86114562, 0.75603865, 0.86597654, 0.86128364, 0.83719807,\n",
       "        0.85162181,        nan,        nan,        nan, 0.87087647,\n",
       "        0.86590752,        nan,        nan,        nan, 0.76080055,\n",
       "        0.83740511, 0.86128364, 0.86121463, 0.86121463, 0.85638371,\n",
       "        0.87543133, 0.87073844,        nan, 0.76556246, 0.8563147 ,\n",
       "               nan, 0.86583851,        nan, 0.85162181,        nan,\n",
       "        0.86597654,        nan, 0.87550035,        nan, 0.75603865,\n",
       "        0.76080055,        nan, 0.87073844,        nan,        nan,\n",
       "        0.87080745,        nan,        nan,        nan, 0.76570048,\n",
       "               nan,        nan,        nan, 0.86121463, 0.842098  ,\n",
       "               nan, 0.81345756, 0.83236715,        nan, 0.85638371,\n",
       "               nan, 0.85638371, 0.85162181, 0.76086957, 0.88026225,\n",
       "               nan, 0.81815045, 0.76086957,        nan,        nan,\n",
       "        0.87073844, 0.88033126, 0.87563837, 0.88026225, 0.75603865,\n",
       "        0.84189096,        nan, 0.84672188, 0.84672188, 0.86590752,\n",
       "        0.76080055, 0.86604555, 0.87080745, 0.75603865,        nan,\n",
       "               nan, 0.75603865, 0.8610766 , 0.76080055, 0.87073844]),\n",
       " 'std_test_score': array([0.05546036, 0.06429363, 0.03544762, 0.04090283, 0.04086917,\n",
       "               nan,        nan, 0.07594184,        nan, 0.07040887,\n",
       "        0.03422118, 0.04728975, 0.04461974, 0.04728975, 0.05452027,\n",
       "        0.04884178, 0.01673821, 0.06663258, 0.0512793 , 0.0410552 ,\n",
       "        0.06660627, 0.05546036, 0.06008336, 0.06999223, 0.04666522,\n",
       "               nan, 0.05546036,        nan, 0.01275978, 0.04104499,\n",
       "               nan, 0.01275978, 0.07866786,        nan, 0.01883666,\n",
       "               nan,        nan,        nan, 0.05131987, 0.05160954,\n",
       "        0.01275978,        nan, 0.06660627, 0.04112128,        nan,\n",
       "        0.0516693 ,        nan, 0.05452027, 0.01042212,        nan,\n",
       "               nan,        nan, 0.04728975,        nan,        nan,\n",
       "        0.06429363, 0.03789417, 0.04088921, 0.04230104, 0.04461974,\n",
       "               nan, 0.06511935, 0.04728975,        nan, 0.05123888,\n",
       "        0.05266049, 0.05884152, 0.02826894, 0.04768631,        nan,\n",
       "        0.04884178, 0.01034138, 0.06510267,        nan, 0.05882865,\n",
       "               nan, 0.04884178, 0.05884152, 0.06008336, 0.04100424,\n",
       "        0.01034138, 0.04892918,        nan, 0.04666522, 0.05366549,\n",
       "        0.05542892, 0.0410552 ,        nan, 0.05840711, 0.00610522,\n",
       "        0.01275978, 0.04666715,        nan, 0.05160954,        nan,\n",
       "        0.06010689,        nan, 0.06660627,        nan, 0.04230104,\n",
       "               nan,        nan,        nan,        nan, 0.04728975,\n",
       "               nan, 0.00517276, 0.0117683 , 0.04884178, 0.06208104,\n",
       "        0.03789417, 0.0513606 , 0.00517276,        nan, 0.04104499,\n",
       "        0.04887074, 0.01034138, 0.07040887, 0.05861444, 0.0251774 ,\n",
       "        0.05884152,        nan,        nan,        nan, 0.04187532,\n",
       "        0.04458044,        nan,        nan,        nan, 0.00517276,\n",
       "        0.02646291, 0.047023  , 0.05266845, 0.05266845, 0.06511935,\n",
       "        0.04768631, 0.04230104,        nan, 0.01758927, 0.05131987,\n",
       "               nan, 0.06474144,        nan, 0.02460044,        nan,\n",
       "        0.04728975,        nan, 0.04884178,        nan, 0.01946928,\n",
       "        0.01275978,        nan, 0.03119377,        nan,        nan,\n",
       "        0.04666522,        nan,        nan,        nan, 0.022957  ,\n",
       "               nan,        nan,        nan, 0.06430015, 0.01171354,\n",
       "               nan, 0.01066604, 0.03046239,        nan, 0.05366549,\n",
       "               nan, 0.05366549, 0.04730576, 0.02328985, 0.05542892,\n",
       "               nan, 0.02952681, 0.01644106,        nan,        nan,\n",
       "        0.04230104, 0.04727393, 0.05862427, 0.04454132, 0.01034138,\n",
       "        0.0516693 ,        nan, 0.0580696 , 0.06879406, 0.04458044,\n",
       "        0.00517276, 0.05254804, 0.04666522, 0.01034138,        nan,\n",
       "               nan, 0.01034138, 0.05802792, 0.00517276, 0.04230104]),\n",
       " 'rank_test_score': array([ 46,   8, 100,   1, 107, 150, 148,  58, 141,  37,  46,  37,  85,\n",
       "         37,  88,  13, 114,  85,  34,  58,  46,  46,  13,  68,  23, 139,\n",
       "         46, 143, 119,   8, 165, 119, 106, 200, 109, 164, 163, 160,  75,\n",
       "         78, 119, 159,  46, 108, 158,  95, 157,  88, 110, 156, 155, 154,\n",
       "         37, 152, 151,   8,  63,  98,  27,  85, 147,  70,  37, 144,   1,\n",
       "          8,  80, 112,  20, 140,  13, 129,  27, 137,  37, 149,  13,  80,\n",
       "         13,  75, 129, 101, 168,  23,  70,   4,  93, 198, 103, 115, 119,\n",
       "         68, 194,  78, 190,  63, 187,  46, 185,  27, 199, 182, 180, 178,\n",
       "         37, 176, 119, 111,  13,  34,  63,  93, 119, 174,   8,  63, 129,\n",
       "         37,  56,  99,  80, 173, 171, 170,  22,  46, 169, 167, 166, 119,\n",
       "         97,  56,  58,  58,  70,  20,  27, 172, 115,  75, 175,  55, 177,\n",
       "         80, 179,  37, 181,  13, 184, 129, 119, 186,  27, 188, 189,  23,\n",
       "        191, 192, 193, 112, 195, 196, 197,  58,  92, 183, 105, 102, 136,\n",
       "         70, 138,  70,  80, 117,   4, 142, 104, 117, 145, 146,  27,   3,\n",
       "          7,   4, 129,  95, 153,  90,  90,  46, 119,  36,  23, 129, 161,\n",
       "        162, 129,  67, 119,  27])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09191a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = pd.DataFrame(rcv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca922c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104693</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.007371</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 143, 'min_samples_split': 3, ...</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.875500</td>\n",
       "      <td>0.048842</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020969</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>12</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>{'n_estimators': 97, 'min_samples_split': 4, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.168712</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>195</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>6</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 195, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.870738</td>\n",
       "      <td>0.053645</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033652</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>6</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>{'n_estimators': 111, 'min_samples_split': 3, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.007841</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 143, 'min_samples_split': 3, ...</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.865977</td>\n",
       "      <td>0.047290</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>11</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>{'n_estimators': 28, 'min_samples_split': 3, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.058670</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 57, 'min_samples_split': 4, '...</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.885024</td>\n",
       "      <td>0.051239</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.061453</td>\n",
       "      <td>0.003548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>195</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>{'n_estimators': 195, 'min_samples_split': 2, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.045361</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>142</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>{'n_estimators': 142, 'min_samples_split': 4, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.039970</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.008031</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>7</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 43, 'min_samples_split': 3, '...</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.861215</td>\n",
       "      <td>0.041055</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.104693      0.007778         0.010425        0.007371   \n",
       "1         0.020969      0.007548         0.000000        0.000000   \n",
       "2         0.168712      0.004580         0.008000        0.006532   \n",
       "3         0.033652      0.003405         0.000000        0.000000   \n",
       "4         0.114943      0.007841         0.015603        0.000036   \n",
       "..             ...           ...              ...             ...   \n",
       "195       0.013333      0.003772         0.000000        0.000000   \n",
       "196       0.058670      0.003771         0.005332        0.003770   \n",
       "197       0.061453      0.003548         0.000000        0.000000   \n",
       "198       0.045361      0.003791         0.000000        0.000000   \n",
       "199       0.039970      0.000074         0.008031        0.000035   \n",
       "\n",
       "    param_n_estimators param_min_samples_split param_max_features  \\\n",
       "0                  143                       3               sqrt   \n",
       "1                   97                       4               sqrt   \n",
       "2                  195                       2               log2   \n",
       "3                  111                       3               log2   \n",
       "4                  143                       3               log2   \n",
       "..                 ...                     ...                ...   \n",
       "195                 28                       3               sqrt   \n",
       "196                 57                       4               sqrt   \n",
       "197                195                       2               sqrt   \n",
       "198                142                       4               log2   \n",
       "199                 43                       3               sqrt   \n",
       "\n",
       "    param_max_depth param_criterion  \\\n",
       "0                 6         entropy   \n",
       "1                12        log_loss   \n",
       "2                 6            gini   \n",
       "3                 6        log_loss   \n",
       "4                 5         entropy   \n",
       "..              ...             ...   \n",
       "195              11        log_loss   \n",
       "196               6         entropy   \n",
       "197               3        log_loss   \n",
       "198              10        log_loss   \n",
       "199               7            gini   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'n_estimators': 143, 'min_samples_split': 3, ...           0.828571   \n",
       "1    {'n_estimators': 97, 'min_samples_split': 4, '...                NaN   \n",
       "2    {'n_estimators': 195, 'min_samples_split': 2, ...           0.814286   \n",
       "3    {'n_estimators': 111, 'min_samples_split': 3, ...                NaN   \n",
       "4    {'n_estimators': 143, 'min_samples_split': 3, ...           0.814286   \n",
       "..                                                 ...                ...   \n",
       "195  {'n_estimators': 28, 'min_samples_split': 3, '...                NaN   \n",
       "196  {'n_estimators': 57, 'min_samples_split': 4, '...           0.842857   \n",
       "197  {'n_estimators': 195, 'min_samples_split': 2, ...                NaN   \n",
       "198  {'n_estimators': 142, 'min_samples_split': 4, ...                NaN   \n",
       "199  {'n_estimators': 43, 'min_samples_split': 3, '...           0.814286   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.942857           0.855072         0.875500        0.048842   \n",
       "1                  NaN                NaN              NaN             NaN   \n",
       "2             0.942857           0.855072         0.870738        0.053645   \n",
       "3                  NaN                NaN              NaN             NaN   \n",
       "4             0.928571           0.855072         0.865977        0.047290   \n",
       "..                 ...                ...              ...             ...   \n",
       "195                NaN                NaN              NaN             NaN   \n",
       "196           0.957143           0.855072         0.885024        0.051239   \n",
       "197                NaN                NaN              NaN             NaN   \n",
       "198                NaN                NaN              NaN             NaN   \n",
       "199           0.914286           0.855072         0.861215        0.041055   \n",
       "\n",
       "     rank_test_score  \n",
       "0                 14  \n",
       "1                136  \n",
       "2                 30  \n",
       "3                143  \n",
       "4                 50  \n",
       "..               ...  \n",
       "195              137  \n",
       "196                2  \n",
       "197              135  \n",
       "198              177  \n",
       "199               75  \n",
       "\n",
       "[200 rows x 16 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2407c635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.885024154589372"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "075d5548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 85,\n",
       " 'min_samples_split': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 6,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "69d17584",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = RandomForestClassifier(n_estimators= 178, min_samples_split= 2, max_features= 'sqrt', max_depth= 13, criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3bb5dc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(criterion='entropy', max_depth=13, max_features='sqrt',\n",
      "                       n_estimators=178)\n"
     ]
    }
   ],
   "source": [
    "print(clf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dfaf0f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=6, max_features='sqrt',\n",
       "                       min_samples_split=4, n_estimators=85)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce86c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = rcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be24f062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=6, max_features='sqrt',\n",
       "                       min_samples_split=4, n_estimators=85)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c601bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=6, max_features='sqrt',\n",
       "                       min_samples_split=4, n_estimators=85)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5d140553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666666666666667"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6984ed",
   "metadata": {},
   "source": [
    "# Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a087e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9615c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1fa9dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv= GridSearchCV(clf, ids, cv=3, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c87f4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.84679089 0.83712905 0.86114562 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=5,\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': array([ 2,  9,  4, 11,  9,  1,  5,  8, 13, 11,  4,  1,  1,  1,  2,  7,  1,\n",
       "        9,  2,  6]),\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'min_samples_split': [2, 3, 4],\n",
       "                         'n_estimators': array([159,  85,  34,  50, 186, 151, 158, 163, 101,  47, 178,  85, 143,\n",
       "        63, 154,  44, 189,  50,  53, 187, 105,  52,  40,  84, 127])})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a35201b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.26556603, 0.13151638, 0.06005955, ..., 0.03927469, 0.07256413,\n",
       "        0.07840816]),\n",
       " 'std_fit_time': array([0.00245627, 0.00607434, 0.00249065, ..., 0.01470796, 0.00677888,\n",
       "        0.02576568]),\n",
       " 'mean_score_time': array([0.01789316, 0.00963243, 0.01021838, ..., 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 'std_score_time': array([0.00377551, 0.0068551 , 0.00424159, ..., 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', ..., 'log_loss', 'log_loss',\n",
       "                    'log_loss'],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[2, 2, 2, ..., 6, 6, 6],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['sqrt', 'sqrt', 'sqrt', ..., 'log2', 'log2', 'log2'],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 2, 2, ..., 4, 4, 4],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[159, 85, 34, ..., 40, 84, 127],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 127},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 159},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 34},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 186},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 151},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 158},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 163},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 47},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 178},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 85},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 143},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 63},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 154},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 44},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 189},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 53},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 187},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 105},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 52},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 40},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 84},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 127},\n",
       "  ...],\n",
       " 'split0_test_score': array([0.81428571, 0.78571429, 0.84285714, ...,        nan,        nan,\n",
       "               nan]),\n",
       " 'split1_test_score': array([0.9       , 0.92857143, 0.9       , ...,        nan,        nan,\n",
       "               nan]),\n",
       " 'split2_test_score': array([0.82608696, 0.79710145, 0.84057971, ...,        nan,        nan,\n",
       "               nan]),\n",
       " 'mean_test_score': array([0.84679089, 0.83712905, 0.86114562, ...,        nan,        nan,\n",
       "               nan]),\n",
       " 'std_test_score': array([0.03793173, 0.06482642, 0.02748992, ...,        nan,        nan,\n",
       "               nan]),\n",
       " 'rank_test_score': array([3874, 4176, 2743, ..., 7003, 7993, 9000])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0b0851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = pd.DataFrame(gcv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e2f508ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.265566</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.017893</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_fea...</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.846791</td>\n",
       "      <td>0.037932</td>\n",
       "      <td>3874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.131516</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.009632</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_fea...</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.837129</td>\n",
       "      <td>0.064826</td>\n",
       "      <td>4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060060</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_fea...</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.861146</td>\n",
       "      <td>0.027490</td>\n",
       "      <td>2743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.070426</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_fea...</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.861284</td>\n",
       "      <td>0.035479</td>\n",
       "      <td>2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.292732</td>\n",
       "      <td>0.022705</td>\n",
       "      <td>0.025796</td>\n",
       "      <td>0.007433</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>186</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_fea...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.842098</td>\n",
       "      <td>0.035009</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>0.120080</td>\n",
       "      <td>0.007418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 6, 'max...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>0.057487</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 6, 'max...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>0.039275</td>\n",
       "      <td>0.014708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 6, 'max...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>0.072564</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 6, 'max...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>0.078408</td>\n",
       "      <td>0.025766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>127</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 6, 'max...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.265566      0.002456         0.017893        0.003776   \n",
       "1          0.131516      0.006074         0.009632        0.006855   \n",
       "2          0.060060      0.002491         0.010218        0.004242   \n",
       "3          0.070426      0.004104         0.007334        0.010372   \n",
       "4          0.292732      0.022705         0.025796        0.007433   \n",
       "...             ...           ...              ...             ...   \n",
       "8995       0.120080      0.007418         0.000000        0.000000   \n",
       "8996       0.057487      0.008147         0.000000        0.000000   \n",
       "8997       0.039275      0.014708         0.000000        0.000000   \n",
       "8998       0.072564      0.006779         0.000000        0.000000   \n",
       "8999       0.078408      0.025766         0.000000        0.000000   \n",
       "\n",
       "     param_criterion param_max_depth param_max_features  \\\n",
       "0               gini               2               sqrt   \n",
       "1               gini               2               sqrt   \n",
       "2               gini               2               sqrt   \n",
       "3               gini               2               sqrt   \n",
       "4               gini               2               sqrt   \n",
       "...              ...             ...                ...   \n",
       "8995        log_loss               6               log2   \n",
       "8996        log_loss               6               log2   \n",
       "8997        log_loss               6               log2   \n",
       "8998        log_loss               6               log2   \n",
       "8999        log_loss               6               log2   \n",
       "\n",
       "     param_min_samples_split param_n_estimators  \\\n",
       "0                          2                159   \n",
       "1                          2                 85   \n",
       "2                          2                 34   \n",
       "3                          2                 50   \n",
       "4                          2                186   \n",
       "...                      ...                ...   \n",
       "8995                       4                105   \n",
       "8996                       4                 52   \n",
       "8997                       4                 40   \n",
       "8998                       4                 84   \n",
       "8999                       4                127   \n",
       "\n",
       "                                                 params  split0_test_score  \\\n",
       "0     {'criterion': 'gini', 'max_depth': 2, 'max_fea...           0.814286   \n",
       "1     {'criterion': 'gini', 'max_depth': 2, 'max_fea...           0.785714   \n",
       "2     {'criterion': 'gini', 'max_depth': 2, 'max_fea...           0.842857   \n",
       "3     {'criterion': 'gini', 'max_depth': 2, 'max_fea...           0.814286   \n",
       "4     {'criterion': 'gini', 'max_depth': 2, 'max_fea...           0.800000   \n",
       "...                                                 ...                ...   \n",
       "8995  {'criterion': 'log_loss', 'max_depth': 6, 'max...                NaN   \n",
       "8996  {'criterion': 'log_loss', 'max_depth': 6, 'max...                NaN   \n",
       "8997  {'criterion': 'log_loss', 'max_depth': 6, 'max...                NaN   \n",
       "8998  {'criterion': 'log_loss', 'max_depth': 6, 'max...                NaN   \n",
       "8999  {'criterion': 'log_loss', 'max_depth': 6, 'max...                NaN   \n",
       "\n",
       "      split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0              0.900000           0.826087         0.846791        0.037932   \n",
       "1              0.928571           0.797101         0.837129        0.064826   \n",
       "2              0.900000           0.840580         0.861146        0.027490   \n",
       "3              0.900000           0.869565         0.861284        0.035479   \n",
       "4              0.885714           0.840580         0.842098        0.035009   \n",
       "...                 ...                ...              ...             ...   \n",
       "8995                NaN                NaN              NaN             NaN   \n",
       "8996                NaN                NaN              NaN             NaN   \n",
       "8997                NaN                NaN              NaN             NaN   \n",
       "8998                NaN                NaN              NaN             NaN   \n",
       "8999                NaN                NaN              NaN             NaN   \n",
       "\n",
       "      rank_test_score  \n",
       "0                3874  \n",
       "1                4176  \n",
       "2                2743  \n",
       "3                2458  \n",
       "4                3994  \n",
       "...               ...  \n",
       "8995             7000  \n",
       "8996             7001  \n",
       "8997             7003  \n",
       "8998             7993  \n",
       "8999             9000  \n",
       "\n",
       "[9000 rows x 16 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "deaf9d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8994478951000691"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "140828da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 85}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "610bfee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=6, max_features='sqrt',\n",
       "                       min_samples_split=4, n_estimators=85)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "74c3b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = gcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "91e751e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=4, max_features='log2',\n",
       "                       min_samples_split=4, n_estimators=85)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b8f454da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=4, max_features='log2',\n",
       "                       min_samples_split=4, n_estimators=85)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1cf8f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ebb20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
